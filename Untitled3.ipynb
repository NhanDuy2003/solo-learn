{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNDgOq3DIzyMKL8fIh8Miyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NhanDuy2003/solo-learn/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQlhDhQHoA6a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from solo.args.knn import parse_args_knn\n",
        "from solo.data.classification_dataloader import (\n",
        "    prepare_dataloaders,\n",
        "    prepare_datasets,\n",
        "    prepare_transforms,\n",
        ")\n",
        "from solo.methods import METHODS\n",
        "from solo.utils.knn import WeightedKNNClassifier\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_features(loader: DataLoader, model: nn.Module) -> Tuple[torch.Tensor]:\n",
        "    \"\"\"Extract features from a data loader using a model.\n",
        "\n",
        "    Args:\n",
        "        loader (DataLoader): dataloader for a dataset.\n",
        "        model (nn.Module): torch module used to extract features.\n",
        "\n",
        "    Returns:\n",
        "        Tuple(torch.Tensor): tuple containing the backbone features, projector features and labels.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    backbone_features, proj_features, labels = [], [], []\n",
        "    for im, lab in tqdm(loader):\n",
        "        im = im.cuda(non_blocking=True)\n",
        "        lab = lab.cuda(non_blocking=True)\n",
        "        outs = model(im)\n",
        "        backbone_features.append(outs[\"feats\"].detach())\n",
        "        proj_features.append(outs[\"z\"])\n",
        "        labels.append(lab)\n",
        "    model.train()\n",
        "    backbone_features = torch.cat(backbone_features)\n",
        "    proj_features = torch.cat(proj_features)\n",
        "    labels = torch.cat(labels)\n",
        "    return backbone_features, proj_features, labels\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_knn(\n",
        "    train_features: torch.Tensor,\n",
        "    train_targets: torch.Tensor,\n",
        "    test_features: torch.Tensor,\n",
        "    test_targets: torch.Tensor,\n",
        "    k: int,\n",
        "    T: float,\n",
        "    distance_fx: str,\n",
        ") -> Tuple[float]:\n",
        "    \"\"\"Runs offline knn on a train and a test dataset.\n",
        "\n",
        "    Args:\n",
        "        train_features (torch.Tensor, optional): train features.\n",
        "        train_targets (torch.Tensor, optional): train targets.\n",
        "        test_features (torch.Tensor, optional): test features.\n",
        "        test_targets (torch.Tensor, optional): test targets.\n",
        "        k (int): number of neighbors.\n",
        "        T (float): temperature for the exponential. Only used with cosine\n",
        "            distance.\n",
        "        distance_fx (str): distance function.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float]: tuple containing the the knn acc@1 and acc@5 for the model.\n",
        "    \"\"\"\n",
        "\n",
        "    # build knn\n",
        "    knn = WeightedKNNClassifier(\n",
        "        k=k,\n",
        "        T=T,\n",
        "        distance_fx=distance_fx,\n",
        "    )\n",
        "\n",
        "    # add features\n",
        "    knn(\n",
        "        train_features=train_features,\n",
        "        train_targets=train_targets,\n",
        "        test_features=test_features,\n",
        "        test_targets=test_targets,\n",
        "    )\n",
        "\n",
        "    # compute\n",
        "    acc1, acc5 = knn.compute()\n",
        "\n",
        "    # free up memory\n",
        "    del knn\n",
        "\n",
        "    return acc1, acc5\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parse_args_knn()\n",
        "\n",
        "    # build paths\n",
        "    ckpt_dir = Path(args.pretrained_checkpoint_dir)\n",
        "    args_path = ckpt_dir / \"args.json\"\n",
        "    ckpt_path = [ckpt_dir / ckpt for ckpt in os.listdir(ckpt_dir) if ckpt.endswith(\".ckpt\")][0]\n",
        "\n",
        "    # load arguments\n",
        "    with open(args_path) as f:\n",
        "        method_args = json.load(f)\n",
        "\n",
        "    # build the model\n",
        "    model = METHODS[method_args[\"method\"]].load_from_checkpoint(\n",
        "        ckpt_path, strict=False, **method_args\n",
        "    )\n",
        "    model.cuda()\n",
        "\n",
        "    # prepare data\n",
        "    _, T = prepare_transforms(args.dataset)\n",
        "    train_dataset, val_dataset = prepare_datasets(\n",
        "        args.dataset,\n",
        "        T_train=T,\n",
        "        T_val=T,\n",
        "        train_data_path=args.train_data_path,\n",
        "        val_data_path=args.val_data_path,\n",
        "        data_format=args.data_format,\n",
        "    )\n",
        "    train_loader, val_loader = prepare_dataloaders(\n",
        "        train_dataset,\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers,\n",
        "    )\n",
        "\n",
        "    # extract train features\n",
        "    train_features_bb, train_features_proj, train_targets = extract_features(train_loader, model)\n",
        "    train_features = {\"backbone\": train_features_bb, \"projector\": train_features_proj}\n",
        "\n",
        "    # extract test features\n",
        "    test_features_bb, test_features_proj, test_targets = extract_features(val_loader, model)\n",
        "    test_features = {\"backbone\": test_features_bb, \"projector\": test_features_proj}\n",
        "\n",
        "    # run k-nn for all possible combinations of parameters\n",
        "    for feat_type in args.feature_type:\n",
        "        print(f\"\\n### {feat_type.upper()} ###\")\n",
        "        for k in args.k:\n",
        "            for distance_fx in args.distance_function:\n",
        "                temperatures = args.temperature if distance_fx == \"cosine\" else [None]\n",
        "                for T in temperatures:\n",
        "                    print(\"---\")\n",
        "                    print(f\"Running k-NN with params: distance_fx={distance_fx}, k={k}, T={T}...\")\n",
        "                    acc1, acc5 = run_knn(\n",
        "                        train_features=train_features[feat_type],\n",
        "                        train_targets=train_targets,\n",
        "                        test_features=test_features[feat_type],\n",
        "                        test_targets=test_targets,\n",
        "                        k=k,\n",
        "                        T=T,\n",
        "                        distance_fx=distance_fx,\n",
        "                    )\n",
        "                    print(f\"Result: acc@1={acc1}, acc@5={acc5}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}